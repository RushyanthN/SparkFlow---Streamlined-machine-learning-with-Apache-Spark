# Spark ML Project

A comprehensive Apache Spark Machine Learning project demonstrating various ML algorithms and techniques using PySpark.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
- [Data](#data)
- [Algorithms Implemented](#algorithms-implemented)
- [Results](#results)
- [Contributing](#contributing)
- [License](#license)

## ğŸ” Overview

This project showcases machine learning implementations using Apache Spark and PySpark, including:

- **Regression Analysis**: Linear regression for fare prediction
- **Classification**: Logistic regression and SVM
- **Clustering**: K-means clustering
- **Topic Modeling**: Latent Dirichlet Allocation (LDA)
- **Performance Analysis**: Spark performance benchmarking

## âœ¨ Features

- **Multiple ML Algorithms**: Regression, classification, clustering, and topic modeling
- **Real-world Dataset**: NYC taxi fare prediction with comprehensive data analysis
- **Performance Benchmarking**: Comparative analysis of different models
- **Data Preprocessing**: Outlier detection, feature engineering, and data cleaning
- **Visualization**: Performance plots and data analysis charts

## ğŸ“ Project Structure

```
spark_ml/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ Indy_rainfall.csv
â”‚   â”‚   â”œâ”€â”€ kmeans_data.txt
â”‚   â”‚   â”œâ”€â”€ linearReg_data.txt
â”‚   â”‚   â”œâ”€â”€ logistic_data.txt
â”‚   â”‚   â”œâ”€â”€ sample_kmeans_data.txt
â”‚   â”‚   â”œâ”€â”€ sample_lda_libsvm_data.txt
â”‚   â”‚   â”œâ”€â”€ sample_libsvm_data.txt
â”‚   â”‚   â””â”€â”€ svm_data.txt
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Spark_ML.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ regression.py
â”‚   â”œâ”€â”€ classification.py
â”‚   â”œâ”€â”€ clustering.py
â”‚   â””â”€â”€ topic_modeling.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ setup_guide.md
â”‚   â””â”€â”€ algorithm_explanations.md
â””â”€â”€ results/
    â””â”€â”€ spark_performance.png
```

## ğŸ›  Prerequisites

- Python 3.7+
- Java 8 or 11
- Apache Spark 3.2.0
- Jupyter Notebook (for interactive analysis)

## ğŸ“¦ Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd spark_ml
   ```

2. **Install Java (if not already installed)**
   ```bash
   # Ubuntu/Debian
   sudo apt-get install openjdk-8-jdk-headless
   
   # macOS
   brew install openjdk@8
   
   # Windows
   # Download and install from Oracle or OpenJDK
   ```

3. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up Spark environment**
   ```bash
   # Download and extract Spark
   wget https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz
   tar xf spark-3.2.0-bin-hadoop3.2.tgz
   
   # Set environment variables
   export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
   export SPARK_HOME=spark-3.2.0-bin-hadoop3.2
   export PATH=$PATH:$SPARK_HOME/bin
   ```

## ğŸš€ Usage

### Running the Jupyter Notebook

```bash
jupyter notebook notebooks/Spark_ML.ipynb
```

### Running Python Scripts

```bash
# Run regression analysis
python src/regression.py

# Run classification
python src/classification.py

# Run clustering
python src/clustering.py
```

### Interactive Spark Session

```python
from pyspark.sql import SparkSession
import findspark

findspark.init()
spark = SparkSession.builder.master("local[*]").getOrCreate()
```

## ğŸ“Š Data

The project uses several datasets:

- **NYC Taxi Data**: For fare prediction and analysis
- **Sample Datasets**: Various ML algorithm demonstrations
- **Rainfall Data**: Environmental data analysis

All data files are located in the `data/raw/` directory.

## ğŸ¤– Algorithms Implemented

### 1. Linear Regression
- **Purpose**: Fare prediction based on distance and duration
- **Features**: Distance, duration, time of day
- **Performance**: RÂ² score evaluation

### 2. Logistic Regression
- **Purpose**: Binary classification
- **Features**: Multi-dimensional feature vectors
- **Evaluation**: Training error analysis

### 3. K-means Clustering
- **Purpose**: Data clustering and pattern recognition
- **Parameters**: Configurable number of clusters
- **Visualization**: Cluster center analysis

### 4. Latent Dirichlet Allocation (LDA)
- **Purpose**: Topic modeling and text analysis
- **Parameters**: Number of topics, iterations
- **Output**: Topic distributions and term weights

## ğŸ“ˆ Results

The project includes performance analysis comparing different models:

- **Model M1**: Distance-based fare prediction
- **Model M2**: Distance + duration-based prediction
- **Performance Metrics**: RÂ² score, execution time analysis
- **Visualization**: Performance comparison charts

## ğŸ”§ Configuration

Key configuration parameters:

```python
# Spark Configuration
spark.conf.set("spark.sql.legacy.timeParserPolicy", "LEGACY")

# Model Parameters
NUM_SAMPLES = 1000000  # For Monte Carlo simulation
K_CLUSTERS = 2         # For K-means
LDA_TOPICS = 10        # For topic modeling
```

## ğŸ“š Documentation

- **Setup Guide**: `docs/setup_guide.md`
- **Algorithm Explanations**: `docs/algorithm_explanations.md`
- **API Reference**: Inline code documentation

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Contact

For questions or support, please open an issue in the repository.

---

**Note**: This project is for educational purposes and demonstrates various machine learning techniques using Apache Spark.
